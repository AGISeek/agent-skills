#!/usr/bin/env python3
# -*- coding: utf-8 -*-
"""
Qwen3-TTS MLX æ‰¹é‡é…éŸ³è„šæœ¬
ä¸“ä¸º Apple Silicon (M1/M2/M3/M4) ä¼˜åŒ–

ä¾èµ–å®‰è£…ï¼š
    pip install mlx-audio soundfile numpy

ä½¿ç”¨ç¤ºä¾‹ï¼š
    python batch_dubbing.py --input dubbing.json --out-dir outputs
"""

import argparse
import json
import subprocess
import sys
from pathlib import Path
from datetime import datetime


# é»˜è®¤æ¨¡å‹
DEFAULT_MODEL = "mlx-community/Qwen3-TTS-12Hz-0.6B-CustomVoice-4bit"


def load_dubbing_script(input_path: str) -> list:
    """åŠ è½½é…éŸ³ç¨¿ JSON"""
    with open(input_path, "r", encoding="utf-8") as f:
        return json.load(f)


def generate_segment(text: str, voice: str, lang_code: str, instruct: str,
                    output_path: str, model: str) -> bool:
    """ç”Ÿæˆå•ä¸ªè¯­éŸ³ç‰‡æ®µ"""
    cmd = [
        sys.executable, "-m", "mlx_audio.tts.generate",
        "--model", model,
        "--text", text,
        "--voice", voice,
        "--lang_code", lang_code,
        "--output_path", output_path,
    ]

    if instruct:
        cmd.extend(["--instruct", instruct])

    result = subprocess.run(cmd, capture_output=True)
    return result.returncode == 0


def merge_audio_files(segment_files: list, output_path: str,
                     silence_gap: float, character_switch_gap: float,
                     speakers: list) -> bool:
    """ä½¿ç”¨ FFmpeg åˆå¹¶éŸ³é¢‘æ–‡ä»¶"""
    import tempfile

    # åˆ›å»º FFmpeg è¾“å…¥æ–‡ä»¶åˆ—è¡¨
    with tempfile.NamedTemporaryFile(mode='w', suffix='.txt', delete=False) as f:
        prev_speaker = None
        for i, (seg_file, speaker) in enumerate(zip(segment_files, speakers)):
            f.write(f"file '{seg_file}'\n")

            # æ·»åŠ é™éŸ³
            if i < len(segment_files) - 1:
                gap = character_switch_gap if prev_speaker and prev_speaker != speaker else silence_gap
                # FFmpeg éœ€è¦é™éŸ³æ–‡ä»¶ï¼Œè¿™é‡Œç”¨ anullsrc ç”Ÿæˆ
                f.write(f"file 'anullsrc=r=24000:cl=mono:d={gap}'\n")

            prev_speaker = speaker

        list_file = f.name

    # ç®€åŒ–ç‰ˆï¼šç›´æ¥æ‹¼æ¥ï¼ˆä¸åŠ é™éŸ³ï¼‰
    cmd = [
        "ffmpeg", "-y", "-f", "concat", "-safe", "0",
        "-i", list_file,
        "-c", "copy", output_path
    ]

    # å°è¯•ç®€å•æ‹¼æ¥
    try:
        import numpy as np
        import soundfile as sf

        all_audio = []
        sample_rate = 24000

        for i, (seg_file, speaker) in enumerate(zip(segment_files, speakers)):
            audio, sr = sf.read(seg_file)
            all_audio.append(audio)

            # æ·»åŠ é™éŸ³
            if i < len(segment_files) - 1:
                gap = character_switch_gap if prev_speaker and prev_speaker != speaker else silence_gap
                silence = np.zeros(int(sample_rate * gap), dtype=np.float32)
                all_audio.append(silence)

            prev_speaker = speaker

        final_audio = np.concatenate(all_audio)
        sf.write(output_path, final_audio, sample_rate)
        return True
    except Exception as e:
        print(f"åˆå¹¶å¤±è´¥: {e}")
        return False


def run_batch_dubbing(args):
    """æ‰¹é‡ç”Ÿæˆé…éŸ³"""
    # åŠ è½½é…éŸ³ç¨¿
    print(f"ğŸ“„ åŠ è½½é…éŸ³ç¨¿: {args.input}")
    segments = load_dubbing_script(args.input)
    print(f"   å…± {len(segments)} ä¸ªç‰‡æ®µ")

    # å‡†å¤‡è¾“å‡ºç›®å½•
    out_dir = Path(args.out_dir).expanduser()
    out_dir.mkdir(parents=True, exist_ok=True)
    segments_dir = out_dir / "segments"
    segments_dir.mkdir(exist_ok=True)

    model = args.model or DEFAULT_MODEL
    print(f"ğŸ”„ ä½¿ç”¨æ¨¡å‹: {model}")

    segment_files = []
    speakers = []

    for i, seg in enumerate(segments):
        text = seg.get("text", "")
        voice = seg.get("voice", seg.get("speaker", "Vivian"))  # å…¼å®¹ speaker å­—æ®µ
        lang_code = seg.get("lang_code", seg.get("lang", "Chinese"))  # å…¼å®¹ lang å­—æ®µ
        instruct = seg.get("instruct", "")

        print(f"\nğŸ™ï¸ [{i+1}/{len(segments)}] ç”Ÿæˆ: {text[:30]}...")
        print(f"   Voice: {voice}, æƒ…æ„Ÿ: {instruct or 'é»˜è®¤'}")

        # ç”Ÿæˆè¯­éŸ³
        segment_path = segments_dir / f"seg_{i+1:03d}_{voice}.wav"
        success = generate_segment(
            text=text,
            voice=voice,
            lang_code=lang_code,
            instruct=instruct,
            output_path=str(segment_path),
            model=model
        )

        if success:
            segment_files.append(str(segment_path))
            speakers.append(voice)
            print(f"   âœ… å·²ä¿å­˜: {segment_path.name}")
        else:
            print(f"   âŒ ç”Ÿæˆå¤±è´¥")

    if not segment_files:
        print("\nâŒ æ²¡æœ‰æˆåŠŸç”Ÿæˆä»»ä½•ç‰‡æ®µ")
        return

    # åˆå¹¶éŸ³é¢‘
    print(f"\nğŸ”— åˆå¹¶ {len(segment_files)} ä¸ªç‰‡æ®µ...")
    input_stem = Path(args.input).stem.replace(".dubbing", "")
    final_path = out_dir / f"{input_stem}_final.wav"

    success = merge_audio_files(
        segment_files=segment_files,
        output_path=str(final_path),
        silence_gap=args.silence_gap,
        character_switch_gap=args.character_switch_gap,
        speakers=speakers
    )

    if success:
        print(f"\nâœ… å®Œæˆ!")
        print(f"   ç‰‡æ®µç›®å½•: {segments_dir}")
        print(f"   æœ€ç»ˆæ–‡ä»¶: {final_path}")
    else:
        print(f"\nâš ï¸ åˆå¹¶å¤±è´¥ï¼Œä½†ç‰‡æ®µæ–‡ä»¶å·²ä¿å­˜åœ¨: {segments_dir}")

    # å¤åˆ¶é…éŸ³ç¨¿åˆ°è¾“å‡ºç›®å½•
    import shutil
    shutil.copy(args.input, out_dir / Path(args.input).name)

    # æ¸…ç†ä¸­é—´æ–‡ä»¶
    if args.clean_segments and success:
        print(f"ğŸ§¹ æ¸…ç†ä¸­é—´ç‰‡æ®µ...")
        shutil.rmtree(segments_dir)


def main():
    parser = argparse.ArgumentParser(
        description="Qwen3-TTS MLX æ‰¹é‡é…éŸ³",
        formatter_class=argparse.RawDescriptionHelpFormatter,
        epilog="""
é…éŸ³ç¨¿ JSON æ ¼å¼:
  [
    {"text": "ç¬¬ä¸€æ®µå†…å®¹", "voice": "Vivian", "lang_code": "Chinese", "instruct": "å™è¿°æ€§è¯­æ°”"},
    {"text": "ç¬¬äºŒæ®µå†…å®¹", "voice": "Ryan", "lang_code": "English", "instruct": "å…´å¥‹çš„è¯­æ°”"}
  ]

ç¤ºä¾‹:
  python batch_dubbing.py --input article.dubbing.json --out-dir outputs
        """
    )

    parser.add_argument("--input", required=True, help="é…éŸ³ç¨¿ JSON æ–‡ä»¶è·¯å¾„")
    parser.add_argument("--out-dir", default="./outputs", help="è¾“å‡ºç›®å½• (é»˜è®¤: ./outputs)")
    parser.add_argument("--model", help=f"æ¨¡å‹åç§° (é»˜è®¤: {DEFAULT_MODEL})")
    parser.add_argument("--silence-gap", type=float, default=0.3,
                       help="æ™®é€šæ®µè½é—´é™éŸ³ç§’æ•° (é»˜è®¤: 0.3)")
    parser.add_argument("--character-switch-gap", type=float, default=0.5,
                       help="è§’è‰²åˆ‡æ¢æ—¶é™éŸ³ç§’æ•° (é»˜è®¤: 0.5)")
    parser.add_argument("--clean-segments", action="store_true",
                       help="åˆå¹¶ååˆ é™¤ä¸­é—´ç‰‡æ®µæ–‡ä»¶")

    args = parser.parse_args()

    print("=" * 50)
    print("ğŸ¬ Qwen3-TTS MLX æ‰¹é‡é…éŸ³")
    print("=" * 50)

    run_batch_dubbing(args)


if __name__ == "__main__":
    main()
